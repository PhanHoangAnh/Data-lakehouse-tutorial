<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Guide: Production Configuration for Spark with Iceberg</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fira+Code&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f8fafc;
        }
        .tab-active {
            border-color: #3b82f6;
            color: #3b82f6;
            background-color: #eff6ff;
        }
        .tab-inactive {
            border-color: transparent;
            color: #4b5563;
        }
        .code-block {
            position: relative;
            background-color: #1f2937;
            color: #d1d5db;
            border-radius: 0.5rem;
            padding: 1.5rem;
            overflow-x: auto;
            font-family: 'Fira Code', monospace;
        }
        .code-block pre {
            margin: 0;
            white-space: pre;
        }
        .copy-btn {
            position: absolute;
            top: 0.75rem;
            right: 0.75rem;
            background-color: #4b5563;
            color: #e5e7eb;
            border: none;
            padding: 0.5rem 0.75rem;
            border-radius: 0.375rem;
            cursor: pointer;
            font-size: 0.875rem;
            transition: background-color 0.2s;
        }
        .copy-btn:hover {
            background-color: #6b7280;
        }
        .copy-btn-copied {
            background-color: #16a34a;
        }
        details > summary {
            cursor: pointer;
            list-style: none;
        }
        details > summary::-webkit-details-marker {
            display: none;
        }
        details[open] summary svg.arrow {
            transform: rotate(180deg);
        }
        .icon {
            width: 2rem;
            height: 2rem;
        }
    </style>
</head>
<body class="antialiased text-slate-800">

    <div class="max-w-5xl mx-auto p-4 sm:p-6 lg:p-8">
        <!-- Header -->
        <header class="text-center mb-10">
            <h1 class="text-3xl sm:text-4xl font-bold text-slate-900">Production Configuration for Spark with Iceberg</h1>
            <p class="mt-4 text-lg text-slate-600">An interactive guide to setting up your data lakehouse without repeating configurations.</p>
        </header>

        <!-- Architecture Diagram -->
        <div class="bg-white p-6 rounded-xl shadow-md mb-10">
            <h2 class="text-xl font-semibold text-center mb-6 text-slate-800">Target Architecture</h2>
            <div class="flex flex-wrap justify-center items-center gap-4 sm:gap-8 text-center">
                <div class="flex flex-col items-center p-2">
                    <svg class="icon text-orange-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M11.25 4.5l7.5 7.5-7.5 7.5m-6-15l7.5 7.5-7.5 7.5" /></svg>
                    <span class="font-semibold">Apache Spark</span>
                    <span class="text-sm text-slate-500">Processing Engine</span>
                </div>
                <div class="text-2xl text-slate-300">+</div>
                <div class="flex flex-col items-center p-2">
                    <svg class="icon text-sky-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M20.25 6.375c0 2.278-3.694 4.125-8.25 4.125S3.75 8.653 3.75 6.375m16.5 0c0-2.278-3.694-4.125-8.25-4.125S3.75 4.097 3.75 6.375m16.5 0v11.25c0 2.278-3.694 4.125-8.25 4.125s-8.25-1.847-8.25-4.125V6.375" /></svg>
                    <span class="font-semibold">Apache Iceberg</span>
                    <span class="text-sm text-slate-500">Table Format</span>
                </div>
                <div class="text-2xl text-slate-300">+</div>
                <div class="flex flex-col items-center p-2">
                    <svg class="icon text-indigo-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M20.25 7.5l-.625 10.632a2.25 2.25 0 01-2.247 2.118H6.622a2.25 2.25 0 01-2.247-2.118L3.75 7.5M10 11.25h4M3.375 7.5h17.25c.621 0 1.125-.504 1.125-1.125v-1.5c0-.621-.504-1.125-1.125-1.125H3.375c-.621 0-1.125.504-1.125 1.125v1.5c0 .621.504 1.125 1.125 1.125z" /></svg>
                    <span class="font-semibold">PostgreSQL</span>
                    <span class="text-sm text-slate-500">Metadata Catalog</span>
                </div>
                <div class="text-2xl text-slate-300">+</div>
                <div class="flex flex-col items-center p-2">
                    <svg class="icon text-red-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M2.25 12.75V12A2.25 2.25 0 014.5 9.75h15A2.25 2.25 0 0121.75 12v.75m-8.69-6.44l-2.12-2.12a1.5 1.5 0 00-1.061-.44H4.5A2.25 2.25 0 002.25 6v12a2.25 2.25 0 002.25 2.25h15A2.25 2.25 0 0021.75 18V9a2.25 2.25 0 00-2.25-2.25h-5.379a1.5 1.5 0 01-1.06-.44z" /></svg>
                    <span class="font-semibold">MinIO</span>
                    <span class="text-sm text-slate-500">S3 Storage</span>
                </div>
            </div>
        </div>

        <!-- Tabs -->
        <div class="mb-8">
            <div class="border-b border-slate-200">
                <nav class="-mb-px flex space-x-6" aria-label="Tabs">
                    <button id="tab-bare-metal" class="tab-btn whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm tab-active">Bare-Metal</button>
                    <button id="tab-docker" class="tab-btn whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm tab-inactive">Docker</button>
                    <button id="tab-kubernetes" class="tab-btn whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm tab-inactive">Kubernetes</button>
                </nav>
            </div>
        </div>

        <!-- Content Panes -->
        <main>
            <!-- Case 1: Bare-Metal -->
            <div id="content-bare-metal" class="tab-content space-y-8">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-md">
                    <h2 class="text-2xl font-bold text-slate-900 mb-2">Case 1: On a Single Machine (Bare-Metal/VM)</h2>
                    <p class="text-slate-600 mb-4">Ideal for development or single-node setups. The strategy is to use the <code class="text-sm bg-slate-100 text-red-600 rounded px-1 py-0.5">spark-defaults.conf</code> file, which Spark loads automatically on startup, keeping your code clean.</p>

                    <h3 class="text-lg font-semibold mt-6 mb-2">Step 1: Locate or Create the File</h3>
                    <p class="text-slate-600 mb-4">The file is at <code class="text-sm bg-slate-100 text-red-600 rounded px-1 py-0.5">$SPARK_HOME/conf/spark-defaults.conf</code>. If it doesn't exist, copy the template:</p>
                    <div class="code-block">
                        <button class="copy-btn">Copy</button>
                        <pre><code class="language-bash">cp $SPARK_HOME/conf/spark-defaults.conf.template $SPARK_HOME/conf/spark-defaults.conf</code></pre>
                    </div>

                    <h3 class="text-lg font-semibold mt-6 mb-2">Step 2: Add Configurations</h3>
                    <p class="text-slate-600 mb-4">Edit <code class="text-sm bg-slate-100 text-red-600 rounded px-1 py-0.5">spark-defaults.conf</code> and add these properties:</p>
                    <div class="code-block">
                        <button class="copy-btn">Copy</button>
                        <pre><code class="language-properties"># == Packages and Spark SQL Extensions ==
spark.jars.packages                   org.apache.iceberg:iceberg-aws-bundle:1.5.2,org.postgresql:postgresql:42.7.3
spark.sql.extensions                  org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

# == Iceberg Catalog Configuration (for PostgreSQL + MinIO) ==
spark.sql.catalog.lakehouse           org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.lakehouse.catalog-impl org.apache.iceberg.jdbc.JdbcCatalog
spark.sql.catalog.lakehouse.uri           jdbc:postgresql://localhost:5432/iceberg_catalog
spark.sql.catalog.lakehouse.jdbc.user     iceberg
spark.sql.catalog.lakehouse.jdbc.password your_secure_password
spark.sql.catalog.lakehouse.warehouse     s3a://datalake/warehouse

# == S3A Filesystem Configuration for MinIO ==
spark.hadoop.fs.s3a.endpoint              http://localhost:9000
spark.hadoop.fs.s3a.access.key            minioadmin
spark.hadoop.fs.s3a.secret.key            your_secure_minio_secret
spark.hadoop.fs.s3a.path.style.access     true
spark.hadoop.fs.s3a.impl                  org.apache.hadoop.fs.s3a.S3AFileSystem</code></pre>
                    </div>

                    <div class="mt-4 p-4 bg-blue-50 border border-blue-200 rounded-lg">
                        <h4 class="font-semibold text-blue-800">A Note on Packages</h4>
                        <p class="text-sm text-blue-700 mt-1">
                            Using the <code class="text-xs bg-blue-100 rounded px-1">iceberg-aws-bundle</code> is the modern, clean way to include S3 support. It bundles all necessary AWS and Hadoop dependencies, preventing version conflicts and simplifying configuration.
                        </p>
                    </div>

                    <h3 class="text-lg font-semibold mt-6 mb-2">Result: Simplified Notebook Code</h3>
                    <p class="text-slate-600 mb-4">Your PySpark initialization is now clean and free of configuration clutter. All settings are loaded automatically!</p>
                    <div class="code-block">
                        <button class="copy-btn">Copy</button>
                        <pre><code class="language-python">from pyspark.sql import SparkSession

# All configurations are loaded automatically!
spark = SparkSession.builder.appName("DataLakehouseApp").getOrCreate()

# You can now use the catalog directly
spark.sql("CREATE TABLE IF NOT EXISTS lakehouse.db.my_table (id bigint, data string) USING iceberg")</code></pre>
                    </div>
                </div>
            </div>

            <!-- Case 2: Docker -->
            <div id="content-docker" class="tab-content space-y-8 hidden">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-md">
                    <h2 class="text-2xl font-bold text-slate-900 mb-2">Case 2: Docker Compose Deployment</h2>
                    <p class="text-slate-600 mb-4">The standard for creating portable, reproducible environments. The strategy is to use environment variables in your <code class="text-sm bg-slate-100 text-red-600 rounded px-1 py-0.5">docker-compose.yml</code> file to pass configurations to the Spark container at runtime.</p>
                    
                    <h3 class="text-lg font-semibold mt-6 mb-2">Step 1: The `docker-compose.yml` File</h3>
                    <p class="text-slate-600 mb-4">This file defines all your services. Configurations are passed via the <code class="text-sm bg-slate-100 text-red-600 rounded px-1 py-0.5">SPARK_OPTS</code> environment variable.</p>
                    <div class="code-block">
                        <button class="copy-btn">Copy</button>
                        <pre><code class="language-yaml">version: '3.8'

services:
  postgres:
    image: postgres:14
    container_name: postgres
    environment:
      - POSTGRES_USER=iceberg
      - POSTGRES_PASSWORD=your_secure_password
      - POSTGRES_DB=iceberg_catalog

  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=your_secure_minio_secret
    command: server /data --console-address ":9090"

  spark-jupyter:
    image: jupyter/pyspark-notebook:spark-3.5.1
    container_name: spark-jupyter
    ports: ["8888:8888", "4040:4040"]
    depends_on: [postgres, minio]
    environment:
      SPARK_OPTS: >-
        --packages org.apache.iceberg:iceberg-aws-bundle:1.5.2,org.postgresql:postgresql:42.7.3
        --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
        --conf spark.sql.catalog.lakehouse=org.apache.iceberg.spark.SparkCatalog
        --conf spark.sql.catalog.lakehouse.catalog-impl=org.apache.iceberg.jdbc.JdbcCatalog
        --conf spark.sql.catalog.lakehouse.uri=jdbc:postgresql://postgres:5432/iceberg_catalog
        --conf spark.sql.catalog.lakehouse.jdbc.user=iceberg
        --conf spark.sql.catalog.lakehouse.jdbc.password=your_secure_password
        --conf spark.sql.catalog.lakehouse.warehouse=s3a://datalake/warehouse
        --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000
        --conf spark.hadoop.fs.s3a.access.key=minioadmin
        --conf spark.hadoop.fs.s3a.secret.key=your_secure_minio_secret
        --conf spark.hadoop.fs.s3a.path.style.access=true
        --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
</code></pre>
                    </div>

                    <h3 class="text-lg font-semibold mt-6 mb-2">Step 2: Configuration Breakdown</h3>
                    <p class="text-slate-600 mb-4">Here's a detailed look at the properties passed to <code class="text-sm bg-slate-100 text-red-600 rounded px-1 py-0.5">SPARK_OPTS</code>. Click to expand.</p>

                    <div class="space-y-4">
                        <details class="bg-slate-50 border border-slate-200 rounded-lg p-4">
                            <summary class="font-semibold text-slate-800 flex justify-between items-center">
                                <span>Packages to Download</span>
                                <svg class="w-5 h-5 text-slate-500 transition-transform transform arrow" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M19 9l-7 7-7-7" /></svg>
                            </summary>
                            <div class="mt-3 text-slate-600 space-y-2">
                                <p><code class="text-sm bg-slate-200 rounded px-1">--packages ...</code>: Tells Spark to download a curated list of necessary libraries (JARs).</p>
                                <ul class="list-disc list-inside ml-4 space-y-1">
                                    <li><b>iceberg-aws-bundle:</b> This is the modern, clean way to include S3 support. It bundles all necessary AWS and Hadoop dependencies, preventing version conflicts.</li>
                                    <li><b>postgresql:</b> The JDBC driver needed to connect to your PostgreSQL metadata catalog.</li>
                                </ul>
                            </div>
                        </details>
                        
                        <details class="bg-slate-50 border border-slate-200 rounded-lg p-4">
                            <summary class="font-semibold text-slate-800 flex justify-between items-center">
                                <span>Iceberg Integration & Catalog</span>
                                <svg class="w-5 h-5 text-slate-500 transition-transform transform arrow" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" d="M19 9l-7 7-7-7" /></svg>
                            </summary>
                            <div class="mt-3 text-slate-600 space-y-2">
                                <p><code class="text-sm bg-slate-200 rounded px-1">--conf spark.sql.extensions=...</code>: Plugs Iceberg's special commands (MERGE INTO, time-travel) into Spark SQL.</p>
                                <p><code class="text-sm bg-slate-200 rounded px-1">--conf spark.sql.catalog.lakehouse=...</code>: Registers a new catalog in Spark named <code class="text-sm bg-slate-200 rounded px-1">lakehouse</code>.</p>
                                <p><code class="text-sm bg-slate-200 rounded px-1">--conf ...uri=jdbc:postgresql://postgres...</code>: The connection string for the PostgreSQL database. Note the service name `postgres`.</p>
                                <p><code class="text-sm bg-slate-200 rounded px-1">--conf ...warehouse=s3a://datalake/warehouse</code>: The default location in MinIO for Iceberg data files.</p>
                            </div>
                        </details>
                    </div>
                </div>
            </div>

            <!-- Case 3: Kubernetes -->
            <div id="content-kubernetes" class="tab-content space-y-8 hidden">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-md">
                    <h2 class="text-2xl font-bold text-slate-900 mb-2">Case 3: Kubernetes (K3s) Deployment</h2>
                    <p class="text-slate-600 mb-4">The standard for scalable, cloud-native production deployments. The strategy is to use a custom-built Docker image and pass configurations via the PySpark script.</p>

                    <h3 class="text-lg font-semibold mt-6 mb-2">Step 1: The PySpark Notebook Code</h3>
                    <p class="text-slate-600 mb-4">This is the final, most robust configuration we discovered. It uses <code class="text-sm bg-slate-100 text-red-600 rounded px-1 py-0.5">spark.jars.packages</code> to ensure all dependencies are correctly loaded by the Spark engine, which is critical in a complex containerized environment.</p>
                    <div class="code-block">
                        <button class="copy-btn">Copy</button>
                        <pre><code class="language-python">from pyspark.sql import SparkSession

# This configuration is the most reliable for Kubernetes.
# It explicitly tells the SparkSession which packages to load,
# resolving complex dependency issues.
spark = SparkSession.builder \\
    .appName("K8sDataLakehouseApp") \\
    .config("spark.jars.packages", "org.apache.iceberg:iceberg-aws-bundle:1.5.2,org.postgresql:postgresql:42.7.3") \\
    .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions") \\
    .config("spark.sql.catalog.lakehouse", "org.apache.iceberg.spark.SparkCatalog") \\
    .config("spark.sql.catalog.lakehouse.catalog-impl", "org.apache.iceberg.jdbc.JdbcCatalog") \\
    .config("spark.sql.catalog.lakehouse.uri", "jdbc:postgresql://postgres-catalog:5432/iceberg_catalog") \\
    .config("spark.sql.catalog.lakehouse.warehouse", "s3a://datalake/warehouse") \\
    .config("spark.hadoop.fs.s3a.endpoint", "http://minio:9000") \\
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \\
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \\
    # --- Production Security: Use Kubernetes Secrets ---
    # The following would be loaded from secure environment variables or mounted files
    # .config("spark.sql.catalog.lakehouse.jdbc.user", os.environ.get("DB_USER"))
    # .config("spark.sql.catalog.lakehouse.jdbc.password", os.environ.get("DB_PASSWORD"))
    # .config("spark.hadoop.fs.s3a.access.key", os.environ.get("MINIO_ACCESS_KEY"))
    # .config("spark.hadoop.fs.s3a.secret.key", os.environ.get("MINIO_SECRET_KEY"))
    .getOrCreate()

# For our project, we set them directly for simplicity
spark.conf.set("spark.sql.catalog.lakehouse.jdbc.user", "iceberg")
spark.conf.set("spark.sql.catalog.lakehouse.jdbc.password", "your_secure_password")
spark.conf.set("spark.hadoop.fs.s3a.access.key", "minioadmin")
spark.conf.set("spark.hadoop.fs.s3a.secret.key", "your_secure_minio_secret")
</code></pre>
                    </div>
                </div>
            </div>
        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const tabs = document.querySelectorAll('.tab-btn');
            const contents = document.querySelectorAll('.tab-content');

            tabs.forEach(tab => {
                tab.addEventListener('click', () => {
                    tabs.forEach(t => t.classList.replace('tab-active', 'tab-inactive'));
                    contents.forEach(c => c.classList.add('hidden'));
                    tab.classList.replace('tab-inactive', 'tab-active');
                    document.getElementById(tab.id.replace('tab-', 'content-')).classList.remove('hidden');
                });
            });

            const copyButtons = document.querySelectorAll('.copy-btn');
            copyButtons.forEach(button => {
                button.addEventListener('click', () => {
                    const codeBlock = button.closest('.code-block');
                    const code = codeBlock.querySelector('code').innerText;
                    navigator.clipboard.writeText(code).then(() => {
                        button.textContent = 'Copied!';
                        button.classList.add('copy-btn-copied');
                        setTimeout(() => {
                            button.textContent = 'Copy';
                            button.classList.remove('copy-btn-copied');
                        }, 2000);
                    }).catch(err => console.error('Failed to copy text: ', err));
                });
            });
        });
    </script>

</body>
</html>
